{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f9e8e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1750 files belonging to 25 classes.\n",
      "Found 375 files belonging to 25 classes.\n",
      "Found 375 files belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "\n",
    "BASE_DIR = r\"D:\\SMART_VISION_AI\\smartvision_dataset\"\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE   = (224, 224)\n",
    "\n",
    "NUM_CLASSES = 25\n",
    "\n",
    "train_dir = os.path.join(BASE_DIR, \"classification\", \"train\")\n",
    "val_dir   = os.path.join(BASE_DIR, \"classification\", \"val\")\n",
    "test_dir  = os.path.join(BASE_DIR, \"classification\", \"test\")\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c2c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4. Data augmentation block (applied only on training data)\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),                # random horizontal flip\n",
    "        layers.RandomRotation(0.04),                    # ~ ±15° (15/360 ≈ 0.04)\n",
    "        layers.RandomZoom(0.1),                         # random zoom\n",
    "        layers.RandomContrast(0.2),                     # ±20% contrast\n",
    "        # Brightness jitter using Lambda + tf.image\n",
    "        layers.Lambda(\n",
    "            lambda x: tf.image.random_brightness(x, max_delta=0.2)\n",
    "        ),\n",
    "        # Optional: light color jitter via saturation\n",
    "        layers.Lambda(\n",
    "            lambda x: tf.image.random_saturation(x, lower=0.8, upper=1.2)\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "\n",
    "# Normalization layer (0–1 scaling or ImageNet style)\n",
    "normalization = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d54736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\SMART_VISION_AI\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - accuracy: 0.0313 - loss: 3.4989"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m630s\u001b[0m 11s/step - accuracy: 0.0309 - loss: 3.4421 - val_accuracy: 0.0293 - val_loss: 3.2345 - learning_rate: 1.0000e-04\n",
      "Epoch 2/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.0512 - loss: 3.3057 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m796s\u001b[0m 14s/step - accuracy: 0.0497 - loss: 3.2952 - val_accuracy: 0.0773 - val_loss: 3.1857 - learning_rate: 1.0000e-04\n",
      "Epoch 3/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - accuracy: 0.0589 - loss: 3.2227 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m763s\u001b[0m 14s/step - accuracy: 0.0549 - loss: 3.2327 - val_accuracy: 0.1200 - val_loss: 3.1538 - learning_rate: 1.0000e-04\n",
      "Epoch 4/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - accuracy: 0.0548 - loss: 3.2219 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 13s/step - accuracy: 0.0629 - loss: 3.2152 - val_accuracy: 0.1600 - val_loss: 3.1274 - learning_rate: 1.0000e-04\n",
      "Epoch 5/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - accuracy: 0.0707 - loss: 3.1797 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m714s\u001b[0m 13s/step - accuracy: 0.0777 - loss: 3.1695 - val_accuracy: 0.1973 - val_loss: 3.1023 - learning_rate: 1.0000e-04\n",
      "Epoch 6/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - accuracy: 0.0944 - loss: 3.1293 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1187s\u001b[0m 22s/step - accuracy: 0.0937 - loss: 3.1314 - val_accuracy: 0.2133 - val_loss: 3.0780 - learning_rate: 1.0000e-04\n",
      "Epoch 7/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.1248 - loss: 3.0998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 6s/step - accuracy: 0.1131 - loss: 3.0977 - val_accuracy: 0.2160 - val_loss: 3.0539 - learning_rate: 1.0000e-04\n",
      "Epoch 8/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.1347 - loss: 3.0714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 5s/step - accuracy: 0.1331 - loss: 3.0629 - val_accuracy: 0.2320 - val_loss: 3.0272 - learning_rate: 1.0000e-04\n",
      "Epoch 9/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.1383 - loss: 3.0420"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 5s/step - accuracy: 0.1343 - loss: 3.0423 - val_accuracy: 0.2347 - val_loss: 3.0063 - learning_rate: 1.0000e-04\n",
      "Epoch 10/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.1552 - loss: 3.0362"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 5s/step - accuracy: 0.1531 - loss: 3.0279 - val_accuracy: 0.2640 - val_loss: 2.9857 - learning_rate: 1.0000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.1666 - loss: 2.9923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 5s/step - accuracy: 0.1646 - loss: 2.9947 - val_accuracy: 0.2880 - val_loss: 2.9620 - learning_rate: 1.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 5s/step - accuracy: 0.1783 - loss: 2.9715 - val_accuracy: 0.2693 - val_loss: 2.9436 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 5s/step - accuracy: 0.1697 - loss: 2.9516 - val_accuracy: 0.2800 - val_loss: 2.9200 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.1914 - loss: 2.9245"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 5s/step - accuracy: 0.1926 - loss: 2.9296 - val_accuracy: 0.3040 - val_loss: 2.9006 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.1862 - loss: 2.9033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 5s/step - accuracy: 0.1943 - loss: 2.9099 - val_accuracy: 0.3067 - val_loss: 2.8765 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 5s/step - accuracy: 0.2046 - loss: 2.8864 - val_accuracy: 0.2827 - val_loss: 2.8566 - learning_rate: 1.0000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2050 - loss: 2.8514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 5s/step - accuracy: 0.2057 - loss: 2.8519 - val_accuracy: 0.3227 - val_loss: 2.8289 - learning_rate: 1.0000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 6s/step - accuracy: 0.2251 - loss: 2.8530 - val_accuracy: 0.3173 - val_loss: 2.8120 - learning_rate: 1.0000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 6s/step - accuracy: 0.2303 - loss: 2.8209 - val_accuracy: 0.3200 - val_loss: 2.7889 - learning_rate: 1.0000e-04\n",
      "Epoch 20/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 6s/step - accuracy: 0.2389 - loss: 2.7991 - val_accuracy: 0.3200 - val_loss: 2.7680 - learning_rate: 1.0000e-04\n",
      "Epoch 21/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1705s\u001b[0m 31s/step - accuracy: 0.2480 - loss: 2.7800 - val_accuracy: 0.3173 - val_loss: 2.7520 - learning_rate: 1.0000e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2602 - loss: 2.7471"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 4s/step - accuracy: 0.2514 - loss: 2.7607 - val_accuracy: 0.3413 - val_loss: 2.7255 - learning_rate: 1.0000e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 5s/step - accuracy: 0.2537 - loss: 2.7403 - val_accuracy: 0.3387 - val_loss: 2.7055 - learning_rate: 1.0000e-04\n",
      "Epoch 24/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2521 - loss: 2.7091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 4s/step - accuracy: 0.2389 - loss: 2.7280 - val_accuracy: 0.3653 - val_loss: 2.6848 - learning_rate: 1.0000e-04\n",
      "Epoch 25/25\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 5s/step - accuracy: 0.2514 - loss: 2.7004 - val_accuracy: 0.3520 - val_loss: 2.6663 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# 2.1: Model 1 - VGG16\n",
    "\n",
    "def build_vgg16_model():\n",
    "    inputs = keras.Input(shape=(*IMG_SIZE, 3))\n",
    "    x = data_augmentation(inputs)       # train only\n",
    "    x = normalization(x)\n",
    "\n",
    "    base_model = keras.applications.VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=x\n",
    "    )\n",
    "    base_model.trainable = False        # freeze convolutional base\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"VGG16_smartvision\")\n",
    "    return model\n",
    "def compile_and_train(model, model_name, train_ds, val_ds, epochs=25, lr=1e-4):\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=f\"{model_name}_best.h5\",\n",
    "            monitor=\"val_accuracy\",\n",
    "            save_best_only=True,\n",
    "            mode=\"max\"\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_accuracy\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    return history\n",
    "\n",
    "vgg16_model = build_vgg16_model()\n",
    "history_vgg16 = compile_and_train(vgg16_model, \"vgg16\", train_ds, val_ds, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44de2cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'bed', 'bench', 'bicycle', 'bird', 'bottle', 'bowl', 'bus', 'cake', 'car', 'cat', 'chair', 'couch', 'cow', 'cup', 'dog', 'elephant', 'horse', 'motorcycle', 'person', 'pizza', 'potted plant', 'stop sign', 'traffic light', 'truck']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5338cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "def evaluate_and_collect_metrics(model, model_name, test_ds, class_names, weights_path=None):\n",
    "    # If you saved best weights, load them\n",
    "    if weights_path is not None and os.path.exists(weights_path):\n",
    "        model.load_weights(weights_path)\n",
    "        print(f\"✅ Loaded best weights from {weights_path}\")\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_pred_probs = []\n",
    "\n",
    "    # ----- measure inference time -----\n",
    "    total_time = 0.0\n",
    "    total_images = 0\n",
    "\n",
    "    for images, labels in test_ds:\n",
    "        images_np = images.numpy()\n",
    "        batch_size = images_np.shape[0]\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        probs = model.predict(images_np, verbose=0)\n",
    "        end = time.perf_counter()\n",
    "\n",
    "        total_time += (end - start)\n",
    "        total_images += batch_size\n",
    "\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(preds)\n",
    "        y_pred_probs.append(probs)\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_probs = np.concatenate(y_pred_probs, axis=0)\n",
    "\n",
    "    # ----- basic metrics -----\n",
    "    acc = (y_true == y_pred).mean()\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"weighted\", zero_division=0\n",
    "    )\n",
    "\n",
    "    # ----- top-5 accuracy -----\n",
    "    top5_correct = 0\n",
    "    for i, label in enumerate(y_true):\n",
    "        top5 = np.argsort(y_pred_probs[i])[-5:]\n",
    "        if label in top5:\n",
    "            top5_correct += 1\n",
    "    top5_acc = top5_correct / len(y_true)\n",
    "\n",
    "    # ----- inference time -----\n",
    "    avg_time_per_image = total_time / total_images  # seconds\n",
    "    imgs_per_second = 1.0 / avg_time_per_image if avg_time_per_image > 0 else 0.0\n",
    "\n",
    "    # ----- model size -----\n",
    "    # Save weights temporarily to compute size\n",
    "    temp_weights = f\"{model_name}_temp_for_size.weights.h5\" \n",
    "    model.save_weights(temp_weights)\n",
    "    size_mb = os.path.getsize(temp_weights) / (1024 * 1024)\n",
    "    os.remove(temp_weights)\n",
    "\n",
    "    # ----- classification report & confusion matrix (for plots) -----\n",
    "    print(f\"\\n=== {model_name.upper()} – Classification Report ===\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(f\"\\nConfusion matrix shape: {cm.shape}\")\n",
    "\n",
    "    metrics = {\n",
    "        \"model_name\": model_name,\n",
    "        \"accuracy\": float(acc),\n",
    "        \"precision_weighted\": float(precision),\n",
    "        \"recall_weighted\": float(recall),\n",
    "        \"f1_weighted\": float(f1),\n",
    "        \"top5_accuracy\": float(top5_acc),\n",
    "        \"avg_inference_time_sec_per_image\": float(avg_time_per_image),\n",
    "        \"images_per_second\": float(imgs_per_second),\n",
    "        \"model_size_mb\": float(size_mb),\n",
    "        \"num_parameters\": int(model.count_params()),\n",
    "    }\n",
    "    return metrics, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c60d233d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded best weights from vgg16_best.h5\n",
      "\n",
      "=== VGG16 – Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     airplane       0.57      0.53      0.55        15\n",
      "          bed       0.29      0.33      0.31        15\n",
      "        bench       0.00      0.00      0.00        15\n",
      "      bicycle       0.62      0.33      0.43        15\n",
      "         bird       0.20      0.60      0.30        15\n",
      "       bottle       0.24      0.47      0.32        15\n",
      "         bowl       0.19      0.27      0.22        15\n",
      "          bus       0.23      0.47      0.30        15\n",
      "         cake       0.56      0.33      0.42        15\n",
      "          car       0.08      0.20      0.12        15\n",
      "          cat       0.29      0.33      0.31        15\n",
      "        chair       0.43      0.40      0.41        15\n",
      "        couch       0.00      0.00      0.00        15\n",
      "          cow       0.26      0.33      0.29        15\n",
      "          cup       1.00      0.13      0.24        15\n",
      "          dog       0.67      0.13      0.22        15\n",
      "     elephant       0.33      0.53      0.41        15\n",
      "        horse       0.54      0.47      0.50        15\n",
      "   motorcycle       0.75      0.20      0.32        15\n",
      "       person       0.29      0.13      0.18        15\n",
      "        pizza       0.89      0.53      0.67        15\n",
      " potted plant       0.29      0.40      0.33        15\n",
      "    stop sign       0.39      0.47      0.42        15\n",
      "traffic light       0.29      0.13      0.18        15\n",
      "        truck       0.20      0.07      0.10        15\n",
      "\n",
      "     accuracy                           0.31       375\n",
      "    macro avg       0.38      0.31      0.30       375\n",
      " weighted avg       0.38      0.31      0.30       375\n",
      "\n",
      "\n",
      "Confusion matrix shape: (25, 25)\n"
     ]
    }
   ],
   "source": [
    "vgg_metrics, vgg_cm = evaluate_and_collect_metrics(\n",
    "    vgg16_model, \"vgg16\", test_ds, class_names, \"vgg16_best.h5\"\n",
    ")\n",
    "with open(\"vgg16_metrics.json\", \"w\") as f:\n",
    "    json.dump(vgg_metrics, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2: Model 2 - ResNet50\n",
    "def build_resnet50_model():\n",
    "    inputs = keras.Input(shape=(*IMG_SIZE, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = normalization(x)\n",
    "\n",
    "    base_model = keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=x\n",
    "    )\n",
    "\n",
    "    # Freeze all, then unfreeze last 20 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[-20:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"ResNet50_smartvision\")\n",
    "    return model\n",
    "\n",
    "resnet_model = build_resnet50_model()\n",
    "history_resnet = compile_and_train(resnet_model, \"resnet50\", train_ds, val_ds, epochs=25, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74719c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3: Model 3 - MobileNetV2\n",
    "\n",
    "def build_mobilenetv2_model():\n",
    "    inputs = keras.Input(shape=(*IMG_SIZE, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = normalization(x)\n",
    "\n",
    "    base_model = keras.applications.MobileNetV2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=x\n",
    "    )\n",
    "    base_model.trainable = False  # keep it light & fast\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"MobileNetV2_smartvision\")\n",
    "    return model\n",
    "\n",
    "mobilenet_model = build_mobilenetv2_model()\n",
    "history_mobilenet = compile_and_train(mobilenet_model, \"mobilenetv2\", train_ds, val_ds, epochs=20, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168414f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4: Model 4 - EfficientNetB0\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")   # for GPU speed\n",
    "\n",
    "def build_efficientnetb0_model():\n",
    "    inputs = keras.Input(shape=(*IMG_SIZE, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = normalization(x)\n",
    "\n",
    "    base_model = keras.applications.EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=x\n",
    "    )\n",
    "\n",
    "    # Fine-tune: unfreeze some top layers\n",
    "    for layer in base_model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", dtype=\"float32\")(x)  # force float32 at output\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"EfficientNetB0_smartvision\")\n",
    "    return model\n",
    "\n",
    "effnet_model = build_efficientnetb0_model()\n",
    "history_effnet = compile_and_train(effnet_model, \"efficientnetb0\", train_ds, val_ds, epochs=30, lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2844b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5: Model Comparison & Selection\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_on_test(model, test_ds, model_name):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for images, labels in test_ds:\n",
    "        preds = model.predict(images)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "    print(f\"\\n=== {model_name} TEST REPORT ===\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=False, cmap=\"Blues\",\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names)\n",
    "    plt.title(f\"{model_name} - Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "# Load best weights if needed and evaluate\n",
    "vgg16_model.load_weights(\"vgg16_best.h5\")\n",
    "resnet_model.load_weights(\"resnet50_best.h5\")\n",
    "mobilenet_model.load_weights(\"mobilenetv2_best.h5\")\n",
    "effnet_model.load_weights(\"efficientnetb0_best.h5\")\n",
    "\n",
    "evaluate_on_test(vgg16_model, test_ds, \"VGG16\")\n",
    "evaluate_on_test(resnet_model, test_ds, \"ResNet50\")\n",
    "evaluate_on_test(mobilenet_model, test_ds, \"MobileNetV2\")\n",
    "evaluate_on_test(effnet_model, test_ds, \"EfficientNetB0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
